{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connect to controlHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"./libs\")\n",
    "import json\n",
    "import random\n",
    "import uuid\n",
    "import warnings\n",
    "from os import name\n",
    "from random import *\n",
    "from threading import Condition\n",
    "\n",
    "import jobCtrl as jc\n",
    "import streamsets\n",
    "import streamsets.sdk\n",
    "import utilslib as utl\n",
    "from streamsets.sdk import *\n",
    "from streamsets.sdk.config import *\n",
    "from streamsets.sdk.constants import *\n",
    "from streamsets.sdk.examples import *\n",
    "from streamsets.sdk.exceptions import *\n",
    "from streamsets.sdk.models import *\n",
    "from streamsets.sdk.sch import *\n",
    "from streamsets.sdk.sch_api import *\n",
    "from streamsets.sdk.sch_models import *\n",
    "from streamsets.sdk.sdc import *\n",
    "from streamsets.sdk.sdc_models import *\n",
    "from streamsets.sdk.utils import *\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ------------------------------------------------\n",
    "cfg = utl.Config(\"./config_file_streamsets_sch_trailer.yaml\")\n",
    "cfg.load()\n",
    "# ------------------------------------------------\n",
    "os.environ[\"STREAMSETS_SDK_ACTIVATION_KEY\"] = cfg.getSdkKey()\n",
    "_BASE_URL_ = cfg.getUrlSch()\n",
    "print(_BASE_URL_)\n",
    "_SDC_URL_ = cfg.getUrlSdc()\n",
    "print(_SDC_URL_)\n",
    "_TX_URL_ = cfg.getUrlTx()\n",
    "print(_TX_URL_)\n",
    "\n",
    "# ------------------------------------------------\n",
    "# ------------------------------------------------\n",
    "# ------------------------------------------------\n",
    "\n",
    "ControlHub.VERIFY_SSL_CERTIFICATES = False\n",
    "DataCollector.VERIFY_SSL_CERTIFICATES = False\n",
    "Transformer.VERIFY_SSL_CERTIFICATES = False\n",
    "control_hub = ControlHub(\n",
    "    cfg.getUrlSch(), username=cfg.getUser(), password=cfg.getPassword()\n",
    ")\n",
    "sdc = DataCollector(cfg.getUrlSdc(), control_hub=control_hub)\n",
    "sdc_authoring = control_hub.data_collectors.get(url=cfg.getUrlSdc())\n",
    "tx = control_hub.transformers.get(url=cfg.getUrlTx())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a fragments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 4):\n",
    "    pb = control_hub.get_pipeline_builder(fragment=True, data_collector=sdc_authoring)\n",
    "    s0 = pb.add_stage(\"Jython Evaluator\")\n",
    "    s0.script = \"import os\"\n",
    "\n",
    "    s0.script = (\n",
    "        \" 1 - substring stmt per column that you want to infer from the input dataframe\"\n",
    "    )\n",
    "\n",
    "    #\n",
    "    s1 = pb.add_stage(\"Jython Evaluator\")\n",
    "    s1.script = \"# push by sdk\"\n",
    "\n",
    "    s2 = pb.add_stage(\"Field Remover\")\n",
    "    #     s1.action = \"REMOVE\"\n",
    "    # #\n",
    "    s0 >> s1 >> s2\n",
    "    #\n",
    "    pipeline = pb.build(title=f\"frag_demo_ut_{i}\")\n",
    "    _ = control_hub.publish_pipeline(pipeline)\n",
    "    print(f\"frag_demo_ut_{i}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract fragments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fragments = [\n",
    "    frag\n",
    "    for frag in control_hub.pipelines.get_all(fragment=True)\n",
    "    if frag.name.startswith(\"frag_demo_ut\")\n",
    "]\n",
    "fragments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create pipelines to wrap fragments "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fragment in fragments:\n",
    "    pb = control_hub.get_pipeline_builder(fragment=False, data_collector=sdc_authoring)\n",
    "    s0 = pb.add_stage(\"Azure Data Lake Storage Gen2\", type=\"origin\")\n",
    "    s0.account_fqdn = \"XXXXXXXXXXXXXXXXXXXXXXXXXXXXX\"\n",
    "    s0.secure_connection = True\n",
    "    s0.authentication_method = \"Shared Key\"\n",
    "    s0.account_shared_key = \"XXXXXXXXXXXXXXXXXXXXXXXXXXXX\"\n",
    "    # setattr(s0,\"storage_container_/_file_system\",\"XXXXXXXXXXX\")\n",
    "    s0.configuration.update(\n",
    "        {\n",
    "            \"dataLakeGen2SourceConfigBean.dataLakeConfig.connection.storageContainer\": \"XXXXXXXXXXXXXXXXX\"\n",
    "        }\n",
    "    )\n",
    "    s1 = pb.add_fragment(fragment)\n",
    "    s2 = pb.add_stage(\"Trash\")\n",
    "    _ = s0 >> s1 >> s2\n",
    "    pipeline = pb.build(title=f\"pipe_{fragment.name}\")\n",
    "    _ = control_hub.publish_pipeline(pipeline)\n",
    "    print(f\"pipe_{fragment.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create jobs to execute pipelines - fragments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipes = [\n",
    "    pipe for pipe in control_hub.pipelines.get_all() if pipe.name.startswith(\"pipe_\")\n",
    "]\n",
    "pipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pipe in pipes:\n",
    "    job_builder = control_hub.get_job_builder()\n",
    "    jn = f\"job_{pipe.name}\"\n",
    "    print(jn)\n",
    "\n",
    "    try:\n",
    "        jd = control_hub.jobs.get(job_name=jn)\n",
    "        control_hub.delete_job(jd)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    p = control_hub.pipelines.get(name=pipe.name)\n",
    "    prms = {\"p1\": \"val1\", \"p2\": \"val2\"}\n",
    "\n",
    "    job = job_builder.build(jn, pipeline=p, runtime_parameters=prms, tags=[\"demo/ut\"])\n",
    "    job.enable_time_series_analysis = True\n",
    "    job.enable_failover = True\n",
    "    job.description = jn\n",
    "    job.data_collector_labels = [\"pool_01\"]\n",
    "    control_hub.add_job(job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "28896b762d76329c10dab5730584f7da7bf435fe44680982515501198d4c3649"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
